{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275eabe3",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Capstone: Project 1\n",
    "The code cell provided below is for the reference code to unzip the unput dataset on your local system.\n",
    "\n",
    "#### Note: We do not recommend running the code in the lab environment. The zip file size will delay the code execution and may lead to some unforseen errors. The input files have already been unzipped for use in this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fd6d86d-2fcc-4da5-a39f-c5fa9e495a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shutil\n",
    "#shutil.unpack_archive(\"Images.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74efec2-a056-4ab1-b849-9775035335a8",
   "metadata": {},
   "source": [
    "#### Step 1: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4fd7f9e-e7cf-417e-802d-0c877d10997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35e6d91-3093-430d-86ad-dcd5aa630acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63/2335160996.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  images = np.array(images)\n"
     ]
    }
   ],
   "source": [
    "#### Step 2: Load and preprocess the data\n",
    "\n",
    "# Load the labels from labels.csv\n",
    "labels_df = pd.read_csv('labels.csv', sep=',', header=None)\n",
    "labels_df.columns = ['image_id', 'class', 'x_min', 'y_min', 'x_max', 'y_max']\n",
    "\n",
    "# Adjust the image IDs in the dataframe\n",
    "labels_df['image_id'] = labels_df['image_id'].apply(lambda x: f\"{x:08d}\")\n",
    "\n",
    "# Use iloc to pick the first 1000 labels\n",
    "labels_df = labels_df.iloc[:1000]\n",
    "\n",
    "# Load the corresponding images\n",
    "images_dir = 'Images/'\n",
    "images = []\n",
    "for index, row in labels_df.iterrows():\n",
    "    img_path = os.path.join(images_dir, f\"{row['image_id']}.jpg\")\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        images.append(img)\n",
    "    else:\n",
    "        print(f\"Error loading image: {img_path}\")\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "# Check if images are loaded\n",
    "if len(images) == 0:\n",
    "    print(\"No images loaded. Please check the image paths.\")\n",
    "else:\n",
    "    print(f\"{len(images)} images loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25518c8a-dbfa-4137-a004-0a261b5860e5",
   "metadata": {},
   "source": [
    "#### Step 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02795ea4-caf4-4ecc-b7d2-dbdbcbae846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of vehicle types in the limited dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ae97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address data quality issues arising from the discrepancy between labels and actual image filenames\n",
    "# Sorting the image filenames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d075c-bf25-4378-84c9-0f00c79e3a6e",
   "metadata": {},
   "source": [
    "#### Step 3: Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf54df2-f210-4979-87c8-30e650e4d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(images) > 0:\n",
    "    processed_images = [cv2.resize(img, (224, 224)) for img in images]  # Adjust dimensions as needed\n",
    "    processed_images = np.array(processed_images)\n",
    "    print(\"Images resized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455d19b-f107-4358-8bc5-adf213db0207",
   "metadata": {},
   "source": [
    "#### Step 4:  Prepare the labels and bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acceca-76b5-47b0-ac97-2e9bd1cb3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_df['class'].to_numpy()\n",
    "bounding_boxes = labels_df[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy()\n",
    "\n",
    "# Convert labels to one-hot encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562327d-b92b-47d7-a233-fc65a9a40720",
   "metadata": {},
   "source": [
    "#### Step 5: Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd954ddd-9ed2-488a-b001-1d8495a59775",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, bbox_train, bbox_test = train_test_split(processed_images, labels, bounding_boxes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba87319f-315b-48ce-a41f-00b19b83f055",
   "metadata": {},
   "source": [
    "#### Step 6: Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc294532-a7df-4ec4-880c-c24cbe116e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    vehicle_class = layers.Dense(num_classes, activation='softmax', name='vehicle_class')(x)\n",
    "    bounding_box = layers.Dense(4, name='bounding_box')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=[vehicle_class, bounding_box])\n",
    "    return model\n",
    "\n",
    "input_shape = processed_images[0].shape\n",
    "num_classes = len(unique_labels)\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'vehicle_class': 'sparse_categorical_crossentropy', 'bounding_box': 'mse'},\n",
    "              metrics={'vehicle_class': 'accuracy', 'bounding_box': 'mae'})\n",
    "\n",
    "model.fit(X_train, {'vehicle_class': y_train, 'bounding_box': bbox_train}, epochs=25, validation_data=(X_test, {'vehicle_class': y_test, 'bounding_box': bbox_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b4abe-e9ae-423c-8b3b-84da1dd3bc7a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 7: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36ff96-a6ce-4f8d-8e48-91ad4d6b3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(X_test, {'vehicle_class': y_test, 'bounding_box': bbox_test}, verbose=2)\n",
    "print('\\nTest results:', test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce837c85-b99d-47f2-9afb-1864606e5bb8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 8: Inferencing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36c41b-930c-4f47-bc4c-ed958ff00218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a few sample images for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18839835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on the sample images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2842e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the predicted bounding box coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sample images with predicted bounding boxes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
